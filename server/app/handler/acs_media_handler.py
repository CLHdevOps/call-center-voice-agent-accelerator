"""Handles media streaming to Azure Voice Live API via WebSocket."""

import asyncio
import base64
from datetime import datetime
import json
import logging
import uuid
from pathlib import Path
from typing import Any, Dict, Optional

from azure.identity.aio import ManagedIdentityCredential
from azure.storage.blob import ContentSettings
from azure.storage.blob.aio import BlobServiceClient
from websockets.asyncio.client import connect as ws_connect
from websockets.typing import Data

logger = logging.getLogger(__name__)

# Event type constants
SESSION_CREATED = "session.created"
INPUT_AUDIO_BUFFER_CLEARED = "input_audio_buffer.cleared"
INPUT_AUDIO_BUFFER_SPEECH_STARTED = "input_audio_buffer.speech_started"
INPUT_AUDIO_BUFFER_SPEECH_STOPPED = "input_audio_buffer.speech_stopped"
CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_COMPLETED = "conversation.item.input_audio_transcription.completed"
CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_FAILED = "conversation.item.input_audio_transcription.failed"
RESPONSE_DONE = "response.done"
RESPONSE_AUDIO_TRANSCRIPT_DONE = "response.audio_transcript.done"
RESPONSE_AUDIO_DELTA = "response.audio.delta"
ERROR = "error"


def load_system_prompt(prompt_file: str = "grace_intake_agent.txt") -> str:
    """
    Load system prompt from external configuration file.

    Args:
        prompt_file: Name of the prompt file in server/prompts/ directory

    Returns:
        System prompt text

    Raises:
        FileNotFoundError: If prompt file doesn't exist
    """
    # Get path relative to this file: server/app/handler/acs_media_handler.py
    # Navigate up to server/ and then into prompts/
    handler_dir = Path(__file__).parent
    prompts_dir = handler_dir.parent.parent / "prompts"
    prompt_path = prompts_dir / prompt_file

    try:
        with open(prompt_path, "r", encoding="utf-8") as f:
            instructions = f.read().strip()
            logger.info("[ACSMediaHandler] Loaded system prompt from %s (%d chars)",
                       prompt_path, len(instructions))
            return instructions
    except FileNotFoundError:
        logger.error("[ACSMediaHandler] Prompt file not found: %s", prompt_path)
        # Fallback to basic prompt
        fallback = (
            "You are Grace, a friendly and knowledgeable intake agent for Mercy House and Sacred Grove. "
            "Help callers with questions about the programs and collect their contact information."
        )
        logger.warning("[ACSMediaHandler] Using fallback prompt (%d chars)", len(fallback))
        return fallback
    except Exception as e:
        logger.exception("[ACSMediaHandler] Error loading prompt file: %s", e)
        raise


def session_config():
    """Returns the default session configuration for Voice Live."""
    return {
        "type": "session.update",
        "session": {
            "instructions": load_system_prompt(),
            "turn_detection": {
                "type": "azure_semantic_vad",
                "threshold": 0.25,
                "prefix_padding_ms": 200,
                "silence_duration_ms": 250,
                "remove_filler_words": False,
            },
            "input_audio_transcription": {
                "model": "whisper-1"
            },
            "input_audio_noise_reduction": {"type": "azure_deep_noise_suppression"},
            "input_audio_echo_cancellation": {"type": "server_echo_cancellation"},
            "voice": {
                "name": "en-US-Emma2:DragonHDLatestNeural",
                "type": "azure-standard",
                "temperature": 0.8
            },
        },
    }

class ACSMediaHandler:
    """Manages audio streaming between client and Azure Voice Live API."""

    def __init__(self, config: Dict[str, Any]):
        self.endpoint: str = config["AZURE_VOICE_LIVE_ENDPOINT"]
        self.model: str = config["VOICE_LIVE_MODEL"]
        self.api_key: Optional[str] = config["AZURE_VOICE_LIVE_API_KEY"]
        self.client_id: Optional[str] = config["AZURE_USER_ASSIGNED_IDENTITY_CLIENT_ID"]
        self.storage_account_url: Optional[str] = config.get("AZURE_STORAGE_ACCOUNT_URL")
        self.storage_container: str = config.get("AZURE_STORAGE_CONTAINER", "conversation-logs")
        self.send_queue: asyncio.Queue = asyncio.Queue(maxsize=100)
        self.ws: Optional[Any] = None
        self.send_task: Optional[asyncio.Task] = None
        self.receiver_task: Optional[asyncio.Task] = None
        self.incoming_websocket: Optional[Any] = None
        self.is_raw_audio: bool = True

        # Conversation tracking
        self.session_id: str = self._generate_guid()
        self.conversation_log: list = []
        self.session_start_time: datetime = datetime.now()
        self.last_event_time: Optional[datetime] = None

        # Audio buffering to prevent crackling
        self.current_response_id: Optional[str] = None
        self.is_first_audio_chunk: bool = True

    def _generate_guid(self) -> str:
        return str(uuid.uuid4())

    def _log_conversation_event(self, event_type: str, speaker: str, text: str, metadata: Optional[Dict] = None) -> None:
        """
        Log a conversation event with timing information.

        Args:
            event_type: Type of event (transcript, speech_started, speech_stopped, etc.)
            speaker: Who is speaking (user, assistant, system)
            text: The transcript text or event description
            metadata: Additional event metadata
        """
        now = datetime.now()

        # Calculate time since last event (pause/delay)
        time_since_last = None
        if self.last_event_time:
            time_since_last = (now - self.last_event_time).total_seconds()

        # Calculate time since session start
        elapsed = (now - self.session_start_time).total_seconds()

        event = {
            "timestamp": now.isoformat(),
            "elapsed_seconds": round(elapsed, 3),
            "time_since_last_event": round(time_since_last, 3) if time_since_last else None,
            "event_type": event_type,
            "speaker": speaker,
            "text": text,
            "metadata": metadata or {}
        }

        self.conversation_log.append(event)
        self.last_event_time = now

        logger.debug("[ConversationLog] %s | %s: %s", event_type, speaker, text[:100])

    async def connect(self) -> None:
        """Connects to Azure Voice Live API via WebSocket."""
        try:
            endpoint = self.endpoint.rstrip("/")
            model = self.model.strip()
            url = f"{endpoint}/voice-live/realtime?api-version=2025-05-01-preview&model={model}"
            url = url.replace("https://", "wss://")

            headers = {"x-ms-client-request-id": self._generate_guid()}

            if self.client_id:
                # Use async context manager to auto-close the credential
                async with ManagedIdentityCredential(client_id=self.client_id) as credential:
                    token = await credential.get_token(
                        "https://cognitiveservices.azure.com/.default"
                    )
                    headers["Authorization"] = f"Bearer {token.token}"
                    logger.info("[ACSMediaHandler] Connected to Voice Live API by managed identity")
            else:
                headers["api-key"] = self.api_key
                logger.info("[ACSMediaHandler] Connected to Voice Live API by API key")

            self.ws = await ws_connect(url, additional_headers=headers)
            logger.info("[ACSMediaHandler] WebSocket connection established")

            await self._send_json(session_config())
            await self._send_json({"type": "response.create"})

            self.receiver_task = asyncio.create_task(self._receiver_loop())
            self.send_task = asyncio.create_task(self._sender_loop())
        except Exception as e:
            logger.exception("[ACSMediaHandler] Failed to connect to Voice Live API: %s", e)
            raise

    async def init_incoming_websocket(self, socket: Any, is_raw_audio: bool = True) -> None:
        """Sets up incoming ACS WebSocket."""
        self.incoming_websocket = socket
        self.is_raw_audio = is_raw_audio

    async def audio_to_voicelive(self, audio_b64: str) -> None:
        """Queues audio data to be sent to Voice Live API."""
        await self.send_queue.put(
            json.dumps({"type": "input_audio_buffer.append", "audio": audio_b64})
        )

    async def _send_json(self, obj: Dict[str, Any]) -> None:
        """Sends a JSON object over WebSocket."""
        if self.ws:
            await self.ws.send(json.dumps(obj))

    async def _sender_loop(self) -> None:
        """Continuously sends messages from the queue to the Voice Live WebSocket."""
        try:
            while True:
                msg = await self.send_queue.get()
                if self.ws:
                    await self.ws.send(msg)
        except asyncio.CancelledError:
            logger.info("[ACSMediaHandler] Sender loop cancelled")
            raise
        except Exception:
            logger.exception("[ACSMediaHandler] Sender loop error")

    async def _receiver_loop(self) -> None:
        """Handles incoming events from the Voice Live WebSocket."""
        try:
            async for message in self.ws:
                event = json.loads(message)
                event_type = event.get("type")

                match event_type:
                    case _ if event_type == SESSION_CREATED:
                        session_id = event.get("session", {}).get("id")
                        logger.info("[ACSMediaHandler] Session ID: %s", session_id)

                    case _ if event_type == INPUT_AUDIO_BUFFER_CLEARED:
                        logger.info("[ACSMediaHandler] Input audio buffer cleared")

                    case _ if event_type == INPUT_AUDIO_BUFFER_SPEECH_STARTED:
                        audio_start_ms = event.get("audio_start_ms")
                        logger.info(
                            "[ACSMediaHandler] Voice activity detection started at %s ms",
                            audio_start_ms,
                        )
                        self._log_conversation_event(
                            "speech_started",
                            "user",
                            "User started speaking",
                            {"audio_start_ms": audio_start_ms}
                        )
                        await self.stop_audio()

                    case _ if event_type == INPUT_AUDIO_BUFFER_SPEECH_STOPPED:
                        logger.info("[ACSMediaHandler] Speech stopped")
                        self._log_conversation_event(
                            "speech_stopped",
                            "user",
                            "User stopped speaking",
                            {}
                        )

                    case _ if event_type == CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_COMPLETED:
                        transcript = event.get("transcript")
                        logger.info("[ACSMediaHandler] User: %s", transcript)
                        self._log_conversation_event(
                            "transcript",
                            "user",
                            transcript,
                            {"item_id": event.get("item_id")}
                        )

                    case _ if event_type == CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_FAILED:
                        error_msg = event.get("error")
                        logger.warning("[ACSMediaHandler] Transcription error: %s", error_msg)

                    case _ if event_type == RESPONSE_DONE:
                        response = event.get("response", {})
                        logger.info("[ACSMediaHandler] Response done: Id=%s", response.get("id"))
                        if response.get("status_details"):
                            logger.info(
                                "[ACSMediaHandler] Status details: %s",
                                json.dumps(response["status_details"], indent=2),
                            )

                    case _ if event_type == RESPONSE_AUDIO_TRANSCRIPT_DONE:
                        transcript = event.get("transcript")
                        logger.info("[ACSMediaHandler] AI: %s", transcript)
                        self._log_conversation_event(
                            "transcript",
                            "assistant",
                            transcript,
                            {"response_id": event.get("response_id"), "item_id": event.get("item_id")}
                        )
                        await self.send_message(
                            json.dumps({"Kind": "Transcription", "Text": transcript})
                        )

                    case _ if event_type == RESPONSE_AUDIO_DELTA:
                        delta = event.get("delta")
                        response_id = event.get("response_id")

                        # Track response changes to detect first audio chunk
                        if response_id != self.current_response_id:
                            self.current_response_id = response_id
                            self.is_first_audio_chunk = True

                        if self.is_raw_audio:
                            audio_bytes = base64.b64decode(delta)

                            # Add silence padding to first chunk to prevent crackling
                            if self.is_first_audio_chunk:
                                # 50ms of silence at 24kHz, 16-bit, mono = 2400 samples = 4800 bytes
                                silence_padding = b'\x00' * 2400
                                audio_bytes = silence_padding + audio_bytes
                                self.is_first_audio_chunk = False
                                logger.debug("[ACSMediaHandler] Added silence padding to first audio chunk")

                            await self.send_message(audio_bytes)
                        else:
                            await self.voicelive_to_acs(delta, self.is_first_audio_chunk)
                            if self.is_first_audio_chunk:
                                self.is_first_audio_chunk = False

                    case _ if event_type == ERROR:
                        logger.error("[ACSMediaHandler] Voice Live error: %s", event)

                    case _:
                        logger.debug("[ACSMediaHandler] Other event: %s", event_type)
        except asyncio.CancelledError:
            logger.info("[ACSMediaHandler] Receiver loop cancelled")
            raise
        except Exception:
            logger.exception("[ACSMediaHandler] Receiver loop error")

    async def send_message(self, message: Data) -> None:
        """Sends data back to client WebSocket."""
        try:
            await self.incoming_websocket.send(message)
        except Exception:
            logger.exception("[ACSMediaHandler] Failed to send message")

    async def voicelive_to_acs(self, base64_data: str, add_padding: bool = False) -> None:
        """Converts Voice Live audio delta to ACS audio message."""
        try:
            # Add silence padding to first chunk if requested
            if add_padding:
                audio_bytes = base64.b64decode(base64_data)
                # 50ms of silence at 24kHz, 16-bit, mono = 2400 samples = 4800 bytes
                silence_padding = b'\x00' * 2400
                audio_bytes = silence_padding + audio_bytes
                base64_data = base64.b64encode(audio_bytes).decode('utf-8')
                logger.debug("[ACSMediaHandler] Added silence padding to first ACS audio chunk")

            data = {
                "Kind": "AudioData",
                "AudioData": {"Data": base64_data},
                "StopAudio": None,
            }
            await self.send_message(json.dumps(data))
        except Exception:
            logger.exception("[ACSMediaHandler] Error in voicelive_to_acs")

    async def stop_audio(self) -> None:
        """Sends a StopAudio signal to ACS."""
        stop_audio_data = {"Kind": "StopAudio", "AudioData": None, "StopAudio": {}}
        await self.send_message(json.dumps(stop_audio_data))

    async def acs_to_voicelive(self, stream_data: str) -> None:
        """Processes audio from ACS and forwards to Voice Live if not silent."""
        try:
            data = json.loads(stream_data)
            if data.get("kind") == "AudioData":
                audio_data = data.get("audioData", {})
                if not audio_data.get("silent", True):
                    await self.audio_to_voicelive(audio_data.get("data"))
        except Exception:
            logger.exception("[ACSMediaHandler] Error processing ACS audio")

    async def web_to_voicelive(self, audio_bytes: bytes) -> None:
        """Encodes raw audio bytes and sends to Voice Live API."""
        audio_b64 = base64.b64encode(audio_bytes).decode("ascii")
        await self.audio_to_voicelive(audio_b64)

    async def save_conversation_log(self) -> Optional[Path]:
        """
        Save conversation log to local file and/or Azure Blob Storage.

        Returns:
            Path to the saved log file, or None if no conversation to save
        """
        if not self.conversation_log:
            logger.warning("[ACSMediaHandler] No conversation data to save")
            return None

        # Generate filename with timestamp
        timestamp = self.session_start_time.strftime("%Y%m%d_%H%M%S")
        filename = f"conversation_{timestamp}_{self.session_id[:8]}.json"

        # Calculate session duration
        duration = (datetime.now() - self.session_start_time).total_seconds()

        # Prepare conversation summary
        conversation_data = {
            "session_id": self.session_id,
            "session_start": self.session_start_time.isoformat(),
            "session_duration_seconds": round(duration, 2),
            "total_events": len(self.conversation_log),
            "model": self.model,
            "endpoint": self.endpoint,
            "conversation": self.conversation_log
        }

        conversation_json = json.dumps(conversation_data, indent=2, ensure_ascii=False)

        # Save to Azure Blob Storage if configured
        if self.storage_account_url and self.client_id:
            try:
                async with ManagedIdentityCredential(client_id=self.client_id) as credential:
                    async with BlobServiceClient(
                        account_url=self.storage_account_url,
                        credential=credential
                    ) as blob_service_client:
                        container_client = blob_service_client.get_container_client(self.storage_container)

                        # Create container if it doesn't exist
                        try:
                            await container_client.create_container()
                            logger.info("[ACSMediaHandler] Created container: %s", self.storage_container)
                        except Exception:
                            pass  # Container already exists

                        # Upload blob
                        blob_client = container_client.get_blob_client(filename)
                        await blob_client.upload_blob(
                            conversation_json.encode('utf-8'),
                            overwrite=True,
                            content_settings=ContentSettings(content_type='application/json')
                        )
                        logger.info("[ACSMediaHandler] Conversation log saved to blob storage: %s/%s",
                                   self.storage_container, filename)
            except Exception as e:
                logger.exception("[ACSMediaHandler] Error saving to blob storage: %s", e)

        # Also save locally for development/debugging
        try:
            handler_dir = Path(__file__).parent
            logs_dir = handler_dir.parent.parent / "conversation_logs"
            logs_dir.mkdir(exist_ok=True)
            log_path = logs_dir / filename

            with open(log_path, "w", encoding="utf-8") as f:
                f.write(conversation_json)

            logger.info("[ACSMediaHandler] Conversation log saved locally: %s", log_path)
            return log_path

        except Exception as e:
            logger.exception("[ACSMediaHandler] Error saving local conversation log: %s", e)
            return None

    async def close(self) -> None:
        """Closes WebSocket connection and cancels background tasks."""
        logger.info("[ACSMediaHandler] Closing handler")

        # Save conversation log before closing
        await self.save_conversation_log()

        # Cancel background tasks
        if self.send_task and not self.send_task.done():
            self.send_task.cancel()
            try:
                await self.send_task
            except asyncio.CancelledError:
                pass

        if self.receiver_task and not self.receiver_task.done():
            self.receiver_task.cancel()
            try:
                await self.receiver_task
            except asyncio.CancelledError:
                pass

        # Close WebSocket connection
        if self.ws:
            await self.ws.close()
            self.ws = None

        logger.info("[ACSMediaHandler] Handler closed successfully")
